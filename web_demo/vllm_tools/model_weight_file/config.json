{
    "_name_or_path": "model_weights/Mixtral-8x7B_New/mg2hg",
    "architectures": [
      "MixtralForConditionalGeneration"
    ],
    "auto_map": {
      "AutoConfig": "configuration_mixtral_multimodal.MixtralMultiModalConfig",
      "AutoModel": "modeling_mixtral_multimodal.MixtralForConditionalGeneration"
    },
    "ignore_index": -100,
    "model_type": "mixtral_multimodal",
    "projector_hidden_act": "gelu",
    "audio_projector_hidden_act": "gelu",
    "image_token_index": 51000,
    "audio_token_index": 51001,
    "text_config": {
      "architectures": [
        "MixtralForCausalLM"
      ],
      "attention_dropout": 0.0,
      "bos_token_id": 1,
      "eos_token_id": 2,
      "hidden_act": "silu",
      "hidden_size": 4096,
      "initializer_range": 0.02,
      "intermediate_size": 14336,
      "max_position_embeddings": 32768,
      "model_type": "mixtral",
      "num_attention_heads": 32,
      "num_experts_per_tok": 2,
      "num_hidden_layers": 32,
      "num_key_value_heads": 8,
      "num_local_experts": 8,
      "output_router_logits": false,
      "rms_norm_eps": 1e-05,
      "rope_theta": 1000000.0,
      "router_aux_loss_coef": 0.02,
      "sliding_window": null,
      "tie_word_embeddings": false,
      "torch_dtype": "bfloat16",
      "transformers_version": "4.41.1",
      "use_cache": false,
      "vocab_size": 51760
    },
    "vision_config": {
      "architectures": [
        "InternVisionModel"
      ],
      "auto_map": {
        "AutoConfig": "configuration_intern_vit.InternVisionConfig",
        "AutoModel": "modeling_intern_vit.InternVisionModel"
      },
      "attention_dropout": 0.0,
      "drop_path_rate": 0.1,
      "dropout": 0.0,
      "hidden_act": "gelu",
      "hidden_size": 1024,
      "image_size": 448,
      "initializer_factor": 1.0,
      "initializer_range": 0.02,
      "intermediate_size": 4096,
      "layer_norm_eps": 1e-06,
      "model_type": "intern_vit_6b",
      "norm_type": "layer_norm",
      "num_attention_heads": 16,
      "num_channels": 3,
      "num_hidden_layers": 24,
      "patch_size": 14,
      "qk_normalization": false,
      "qkv_bias": true,
      "torch_dtype": "bfloat16",
      "transformers_version": "4.37.2",
      "use_flash_attn": true
    },
    "audio_config":{
      "_name_or_path": "whale_audio_mini",
      "architectures": [
        "WhaleAudioModel"
      ],
      "attention_dropout": 0.0,
      "auto_map": {
        "AutoConfig": "configuration_whale.WhaleConfig",
        "AutoFeatureExtractor": "processor_whale.WhaleFeatureExtractor",
        "AutoModel": "modeling_whale.WhaleAudioModel"
      },
      "concat_after": false,
      "dropout": 0.1,
      "hidden_act": "relu",
      "hidden_size": 1024,
      "initializer_factor": 0.1,
      "initializer_range": 0.02,
      "input_dim": 80,
      "intermediate_size": 4096,
      "layer_norm_eps": 1e-05,
      "max_position_embeddings": 5000,
      "model_type": "whale",
      "norm_type": "layer_norm",
      "normalize_before": true,
      "num_attention_heads": 16,
      "num_channels": 1,
      "num_hidden_layers": 24,
      "positional_dropout": 0.1,
      "qk_normalization": false,
      "qkv_bias": false,
      "torch_dtype": "float32",
      "transformers_version": "4.42.4",
      "use_flash_attn": false,
      "use_relative_pe": true
    },
    "downsample_ratio": 0.5,
    "dynamic_image_size": true,
    "max_dynamic_patch": 12,
    "min_dynamic_patch": 1,
    "vision_feature_layer": -1,
    "use_thumbnail": true,
    "tokenizer_model_max_length": 4600,
    "tokenizer_padding_side": "right",
    "vocab_size": 51760
  }       
  
